{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from units import CycleGANDataset,Mask_replace\n",
    "from models.generator import Generator\n",
    "from models.discriminator import Discriminator\n",
    "from tqdm import tqdm\n",
    "# 在这个示例中，我们假设已经定义了 `Generator` 和 `Discriminator` 类，以及数据集类 `CycleGANDataset`，并将它们导入到代码中。我们定义了 `gen_A_to_B` 和 `gen_B_to_A` 作为我们的生成器，并定义 `disc_A` 和 `disc_B` 作为我们的判别器。我们使用 `MSELoss` 作为循环一致性损失，使用 `BCEWithLogitsLoss` 作为GAN损失。我们还定义了三个优化器，分别用于优化生成器、判别器A和判别器B。\n",
    "\n",
    "# 在训练循环中，我们首先从数据集中获取一对图像 `A` 和 `B`，并将它们送入模型。我们使用生成器将 `A` 转换为 `B`，并使用另一个生成器将 `B` 转换为 `A`。我们计算生成器的总损失，包括对抗损失、循环一致性损失和身份损失。我们还分别训练两个判别器，将其区分真实图像和生成图像。最后，我们保存模型和生成的图像。\n",
    "\n",
    "# 在训练完成后，我们可以使用训练好的模型生成新的图像。我们加载训练好的\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. 定义生成器和判别器的架构\n",
    "gen_A_to_B = Generator().to(device)\n",
    "gen_B_to_A = Generator().to(device)\n",
    "disc_A = Discriminator().to(device)\n",
    "disc_B = Discriminator().to(device)\n",
    "\n",
    "# 2. 定义损失函数\n",
    "mse_loss = nn.MSELoss()\n",
    "gan_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 3. 定义优化器\n",
    "gen_optim = optim.Adam(list(gen_A_to_B.parameters()) + list(gen_B_to_A.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "disc_A_optim = optim.Adam(disc_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "disc_B_optim = optim.Adam(disc_B.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (initial): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (residual_block): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blcoks): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (last): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_A_to_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.28s/it]"
     ]
    }
   ],
   "source": [
    "# 4. 训练模型\n",
    "num_epochs=3\n",
    "save_path='save/'\n",
    "dataset = CycleGANDataset()  # 自己定义的数据集\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (A, B , _) in tqdm(enumerate(dataloader)):\n",
    "        real_A = A.to(device).float()\n",
    "        real_B = B.to(device).float()\n",
    "\n",
    "        # 训练生成器\n",
    "        gen_optim.zero_grad()\n",
    "        fake_B = gen_A_to_B(real_A)\n",
    "        cycle_A = gen_B_to_A(fake_B)\n",
    "        fake_A = gen_B_to_A(real_B)\n",
    "        cycle_B = gen_A_to_B(fake_A)\n",
    "        idt_A = gen_B_to_A(real_A)\n",
    "        idt_B = gen_A_to_B(real_B)\n",
    "        gen_adv_loss = gan_loss(disc_B(fake_B), torch.ones_like(disc_B(fake_B))).to(device)\n",
    "        gen_cycle_loss = mse_loss(cycle_A, real_A) + mse_loss(cycle_B, real_B)\n",
    "        gen_idt_loss = mse_loss(idt_A, real_A) + mse_loss(idt_B, real_B)\n",
    "        gen_total_loss = gen_adv_loss + 10 * gen_cycle_loss + 5 * gen_idt_loss\n",
    "        gen_total_loss.backward()\n",
    "        gen_optim.step()\n",
    "\n",
    "        # 训练判别器 A\n",
    "        disc_A_optim.zero_grad()\n",
    "        real_A_loss = gan_loss(disc_A(real_A), torch.ones_like(disc_A(real_A)).to(device))\n",
    "        fake_A_loss = gan_loss(disc_A(fake_A.detach()), torch.zeros_like(disc_A(fake_A)).to(device))\n",
    "        disc_A_loss = real_A_loss + fake_A_loss\n",
    "        disc_A_loss.backward()\n",
    "        disc_A_optim.step()\n",
    "\n",
    "        # 训练判别器 B\n",
    "        disc_B_optim.zero_grad()\n",
    "        real_B_loss = gan_loss(disc_B(real_B), torch.ones_like(disc_B(real_B)))\n",
    "        fake_B_loss = gan_loss(disc_B(fake_B.detach()), torch.zeros_like(disc_B(fake_B)))\n",
    "        disc_B_loss = real_B_loss + fake_B_loss\n",
    "        disc_B_loss.backward()\n",
    "        disc_B_optim.step()\n",
    "\n",
    "    # # 每个epoch结束后，保存模型并生成图像\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch {epoch} Over, Disc_A_loss : {round(float(disc_A_loss),2)},  Disc_B_loss : {round(float(disc_B_loss),2)}')\n",
    "        torch.save(gen_A_to_B.state_dict(), f\"{save_path}gen_A_to_B_{epoch}.pt\")\n",
    "        torch.save(gen_B_to_A.state_dict(), f\"{save_path}gen_B_to_A_{epoch}.pt\")\n",
    "        torch.save(disc_A.state_dict(), f\"{save_path}disc_A_{epoch}.pt\")\n",
    "        torch.save(disc_B.state_dict(), f\"{save_path}disc_B_{epoch}.pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 生成 A -> B 的图像\n",
    "        A, _, Mask= dataset[0]\n",
    "        A = torch.Tensor(A).unsqueeze(0).to(device)\n",
    "        B = gen_A_to_B(A)\n",
    "        save_image(B.cpu(), f\"{save_path}gen_A_to_B_{epoch}.png\")\n",
    "        \n",
    "        # 生成 B -> A 的图像\n",
    "        _, B, Mask= dataset[0]\n",
    "        B = torch.Tensor(B).unsqueeze(0).to(device)\n",
    "        A = gen_B_to_A(B)\n",
    "        save_image(A.cpu(), f\"{save_path}gen_B_to_A_{epoch}.png\")\n",
    "\n",
    "\n",
    "#使用模型生成图像\n",
    "#加载训练好的模型\n",
    "gen_A_to_B = Generator()\n",
    "gen_A_to_B.load_state_dict(torch.load(f\"{save_path}gen_A_to_B_{epoch}.pt\"))\n",
    "gen_B_to_A = Generator()\n",
    "gen_B_to_A.load_state_dict(torch.load(f\"{save_path}gen_B_to_A_{epoch}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用模型生成图像\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for i in range(3):\n",
    "    with torch.no_grad():\n",
    "        plt.figure(figsize=(8,4))\n",
    "        idx=np.random.randint(0,len(dataset))\n",
    "        print(idx)\n",
    "        A, _ , Mask= dataset[idx] #3\n",
    "        A = torch.Tensor(A).unsqueeze(0)\n",
    "        B = gen_A_to_B(A)\n",
    "        save_image(B.cpu(), f\"{save_path}generated_image.png\")\n",
    "        id=1342\n",
    "        plt.subplot(131)\n",
    "        plt.title('Original')\n",
    "        real_img=A.cpu()[0].numpy().transpose(1,2,0)\n",
    "        plt.imshow(real_img)\n",
    "        plt.subplot(132)\n",
    "        plt.title('Style')\n",
    "        # 将掩码转换为Numpy数组\n",
    "        fake_img=B.cpu()[0].numpy().transpose(1,2,0)\n",
    "        plt.imshow(fake_img)\n",
    "        # 显示掩码标签\n",
    "        plt.subplot(133)\n",
    "        plt.title('Transform')\n",
    "        plt.imshow(Mask_replace(real_img,fake_img,Mask))\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biobase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4342b7b77d03aa170c0061ccc2d89deb9ee932a6281860c89ed54b64e098c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
